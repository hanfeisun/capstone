{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words in GLOVE: 400000\n",
      "[('uuuuu', 1), ('me', 11), (\"i'm\", 21), ('have', 31), ('so', 41), ('glad', 51), ('be', 61), ('really', 71), ('question', 81), ('name', 91)]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 128, 100)          409600    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128, 100)          45300     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 128, 100)          10100     \n",
      "_________________________________________________________________\n",
      "att_layer_1 (AttLayer)       (None, 100)               100       \n",
      "=================================================================\n",
      "Total params: 465,100\n",
      "Trainable params: 55,500\n",
      "Non-trainable params: 409,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 32, 100), (None, 10)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Downloads/LSTM_rubystar/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mseq_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m \u001b[0mseq_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_embedding_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0mgru_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \"\"\"\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    339\u001b[0m                              \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                              \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                              'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 32, 100), (None, 10)]"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_3/BiasAdd:0' shape=(?, 100) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dense(100)(layers.Flatten()(sentence_embedding_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "lambda_10 (Lambda)           (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, 128, 100)          409600    \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 128, 100)          45300     \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 128, 100)          10100     \n",
      "_________________________________________________________________\n",
      "att_layer_12 (AttLayer)      (None, 100)               100       \n",
      "=================================================================\n",
      "Total params: 465,100\n",
      "Trainable params: 55,500\n",
      "Non-trainable params: 409,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "glove (InputLayer)              (None, 32, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 32, 100)      465100      glove[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sentence (InputLayer)           (None, 32, 15)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 115)      0           time_distributed_11[0][0]        \n",
      "                                                                 sentence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 32, 64)       28416       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "att_layer_13 (AttLayer)         (None, 64)           64          bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "session (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 74)           0           att_layer_13[0][0]               \n",
      "                                                                 session[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 74)           0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 128)          9600        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128)          512         dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 64)           8256        batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64)           256         dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 16)           1040        batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16)           64          dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "softmax_output (Dense)          (None, 6)            102         batch_normalization_24[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 513,410\n",
      "Trainable params: 103,394\n",
      "Non-trainable params: 410,016\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8122 samples, validate on 903 samples\n",
      "Epoch 1/1000\n",
      "7936/8122 [============================>.] - ETA: 2s - loss: 1.9595 - categorical_crossentropy: 1.9595 - acc: 0.1932Epoch 00001: val_acc did not improve\n",
      "8122/8122 [==============================] - 117s 14ms/step - loss: 1.9568 - categorical_crossentropy: 1.9568 - acc: 0.1934 - val_loss: 1.7524 - val_categorical_crossentropy: 1.7524 - val_acc: 0.1849\n",
      "Epoch 2/1000\n",
      "7936/8122 [============================>.] - ETA: 6s - loss: 1.7934 - categorical_crossentropy: 1.7934 - acc: 0.2188 Epoch 00002: val_acc did not improve\n",
      "8122/8122 [==============================] - 290s 36ms/step - loss: 1.7927 - categorical_crossentropy: 1.7927 - acc: 0.2193 - val_loss: 1.7481 - val_categorical_crossentropy: 1.7481 - val_acc: 0.2082\n",
      "Epoch 3/1000\n",
      "7936/8122 [============================>.] - ETA: 35s - loss: 1.7351 - categorical_crossentropy: 1.7351 - acc: 0.2269 Epoch 00003: val_acc did not improve\n",
      "8122/8122 [==============================] - 1531s 188ms/step - loss: 1.7350 - categorical_crossentropy: 1.7350 - acc: 0.2263 - val_loss: 1.7345 - val_categorical_crossentropy: 1.7345 - val_acc: 0.2126\n",
      "Epoch 4/1000\n",
      "7936/8122 [============================>.] - ETA: 2s - loss: 1.6985 - categorical_crossentropy: 1.6985 - acc: 0.2384Epoch 00004: val_acc did not improve\n",
      "8122/8122 [==============================] - 115s 14ms/step - loss: 1.6985 - categorical_crossentropy: 1.6985 - acc: 0.2371 - val_loss: 1.7194 - val_categorical_crossentropy: 1.7194 - val_acc: 0.2148\n",
      "Epoch 5/1000\n",
      "1280/8122 [===>..........................] - ETA: 1:28 - loss: 1.6904 - categorical_crossentropy: 1.6904 - acc: 0.2219"
     ]
    }
   ],
   "source": [
    "\n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.init = initializers.glorot_normal\n",
    "        super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = self.add_weight(name='kernel',\n",
    "                                 shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"glorot_normal\",\n",
    "                                 trainable=True)\n",
    "\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.tanh(K.dot(x, self.W))\n",
    "\n",
    "        ai = K.exp(eij)\n",
    "\n",
    "        weights = ai / tf.expand_dims(K.sum(ai, axis=1), 1)\n",
    "        weighted_input = x * weights\n",
    "\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n",
    "\n",
    "in_sentence = Input(shape=(MAX_WORD_PER_SENTENCE,), dtype='int32')\n",
    "sentence = layers.Lambda(lambda x: x[:, :MAX_SENTENCE_PER_SESSION])(in_sentence)\n",
    "e = Embedding(input_dim=nb_words,\n",
    "              output_dim=EMBEDDING_DIM,\n",
    "              input_length=MAX_WORD_PER_SENTENCE,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False)(sentence)\n",
    "\n",
    "gru_output = e\n",
    "if False:\n",
    "    gru_output = GRU(50, return_sequences=True)(gru_output)\n",
    "gru_output = layers.Bidirectional(GRU(50, return_sequences=True))(gru_output)\n",
    "gru_output = TimeDistributed(Dense(100))(gru_output)\n",
    "gru_output = AttLayer()(gru_output)\n",
    "\n",
    "# gru_output = layers.concatenate([GRU(50)(gru_output), tf.keras.backend.constant([[1]])])\n",
    "encoded_model = Model(inputs=[in_sentence], outputs=[gru_output])\n",
    "print(encoded_model.summary())\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SENTENCE_PER_SESSION, MAX_WORD_PER_SENTENCE), dtype='int32', name='glove')\n",
    "sentence_embedding_input = Input(shape=(MAX_SENTENCE_PER_SESSION, SENTENCE_EMBEDDING_SIZE), dtype='float32',\n",
    "                                 name='sentence')\n",
    "session_embedding_input = Input(shape=(SESSION_EMBEDDING_SIZE,), dtype='float32', name='session')\n",
    "\n",
    "naive = False\n",
    "if not naive:\n",
    "    seq_encoded = TimeDistributed(encoded_model)(sequence_input)\n",
    "    seq_encoded = layers.concatenate([seq_encoded, sentence_embedding_input], axis=2)\n",
    "else:\n",
    "    seq_encoded = sentence_embedding_input\n",
    "    seq_encoded = Dropout(0.2)(seq_encoded)\n",
    "if True:\n",
    "    seq_encoded = layers.Bidirectional(GRU(32, return_sequences=True))(seq_encoded)\n",
    "    seq_encoded = AttLayer()(seq_encoded)\n",
    "else:\n",
    "    seq_encoded = Dense(256, activation='relu')(layers.Flatten()(seq_encoded))\n",
    "    seq_encoded = BatchNormalization()(seq_encoded)\n",
    "seq_encoded = layers.concatenate([seq_encoded, session_embedding_input], axis=1)\n",
    "\n",
    "x = Dropout(0.2)(seq_encoded)\n",
    "gru_output = Dense(128, activation='relu')(x)\n",
    "gru_output = BatchNormalization()(gru_output)\n",
    "\n",
    "gru_output = Dense(64, activation='relu')(gru_output)\n",
    "gru_output = BatchNormalization()(gru_output)\n",
    "\n",
    "gru_output = Dense(16, activation='relu')(gru_output)\n",
    "gru_output = BatchNormalization()(gru_output)\n",
    "\n",
    "gru_output = Dense(6, activation='softmax', name='softmax_output')(gru_output)\n",
    "if REGRESSION:\n",
    "    gru_output = Dense(1, activation='sigmoid', name='scalar_output')(gru_output)\n",
    "\n",
    "model = Model(inputs=[sequence_input, sentence_embedding_input, session_embedding_input], outputs=[gru_output])\n",
    "print(model.summary())\n",
    "\n",
    "if REGRESSION:\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.rmsprop(),\n",
    "                  metrics=[keras.metrics.mse, keras.metrics.binary_crossentropy])\n",
    "else:\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.rmsprop(),\n",
    "                  metrics=[keras.metrics.categorical_crossentropy, \"accuracy\"])\n",
    "\n",
    "if REGRESSION:\n",
    "    y_train = np.argmax(y_train, axis=1).reshape([-1, 1])\n",
    "    y_test = np.argmax(y_test, axis=1).reshape([-1, 1])\n",
    "    y_train = y_train / 5.\n",
    "    y_test = y_test / 5.\n",
    "\n",
    "    model.fit(X_train,\n",
    "              {'scalar_output': y_train},\n",
    "              epochs=30,\n",
    "              batch_size=128,\n",
    "              validation_data=(X_test, {'scalar_output': y_test}),\n",
    "              callbacks=callbacks_list\n",
    "              )\n",
    "else:\n",
    "    model.fit(X_train,\n",
    "              {'softmax_output': y_train},\n",
    "              epochs=1000,\n",
    "              batch_size=256,\n",
    "              validation_data=(X_test, {'softmax_output': y_test}),\n",
    "              callbacks=callbacks_list\n",
    "              )\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9025, 20, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sentence_aux_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 40, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 40, 16)            5232      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 40, 16)            272       \n",
      "_________________________________________________________________\n",
      "att_layer_11 (AttLayer)      (None, 16)                16        \n",
      "=================================================================\n",
      "Total params: 2,005,520\n",
      "Trainable params: 5,520\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence (InputLayer)           (None, 20, 8)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 20, 8)        0           sentence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 20, 16)       816         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "att_layer_12 (AttLayer)         (None, 16)           16          bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "session (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 26)           0           att_layer_12[0][0]               \n",
      "                                                                 session[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           432         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16)           64          dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "softmax_output (Dense)          (None, 6)            102         batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 1,430\n",
      "Trainable params: 1,398\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8122 samples, validate on 903 samples\n",
      "Epoch 1/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.8475 - categorical_crossentropy: 1.8475 - acc: 0.2300Epoch 00001: val_acc did not improve\n",
      "8122/8122 [==============================] - 4s 497us/step - loss: 1.8444 - categorical_crossentropy: 1.8444 - acc: 0.2302 - val_loss: 1.8251 - val_categorical_crossentropy: 1.8251 - val_acc: 0.2049\n",
      "Epoch 2/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.7241 - categorical_crossentropy: 1.7241 - acc: 0.2424Epoch 00002: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 136us/step - loss: 1.7226 - categorical_crossentropy: 1.7226 - acc: 0.2428 - val_loss: 1.7275 - val_categorical_crossentropy: 1.7275 - val_acc: 0.2115\n",
      "Epoch 3/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.6769 - categorical_crossentropy: 1.6769 - acc: 0.2443Epoch 00003: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 132us/step - loss: 1.6761 - categorical_crossentropy: 1.6761 - acc: 0.2446 - val_loss: 1.6665 - val_categorical_crossentropy: 1.6665 - val_acc: 0.2326\n",
      "Epoch 4/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.6442 - categorical_crossentropy: 1.6442 - acc: 0.2446Epoch 00004: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 142us/step - loss: 1.6435 - categorical_crossentropy: 1.6435 - acc: 0.2442 - val_loss: 1.6380 - val_categorical_crossentropy: 1.6380 - val_acc: 0.2137\n",
      "Epoch 5/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.6227 - categorical_crossentropy: 1.6227 - acc: 0.2395Epoch 00005: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 137us/step - loss: 1.6225 - categorical_crossentropy: 1.6225 - acc: 0.2396 - val_loss: 1.6210 - val_categorical_crossentropy: 1.6210 - val_acc: 0.2425\n",
      "Epoch 6/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.6067 - categorical_crossentropy: 1.6067 - acc: 0.2552Epoch 00006: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 134us/step - loss: 1.6070 - categorical_crossentropy: 1.6070 - acc: 0.2549 - val_loss: 1.6063 - val_categorical_crossentropy: 1.6063 - val_acc: 0.2447\n",
      "Epoch 7/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5989 - categorical_crossentropy: 1.5989 - acc: 0.2514Epoch 00007: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 131us/step - loss: 1.5992 - categorical_crossentropy: 1.5992 - acc: 0.2509 - val_loss: 1.5995 - val_categorical_crossentropy: 1.5995 - val_acc: 0.2614\n",
      "Epoch 8/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5906 - categorical_crossentropy: 1.5906 - acc: 0.2616Epoch 00008: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 132us/step - loss: 1.5910 - categorical_crossentropy: 1.5910 - acc: 0.2603 - val_loss: 1.5921 - val_categorical_crossentropy: 1.5921 - val_acc: 0.2547\n",
      "Epoch 9/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5885 - categorical_crossentropy: 1.5885 - acc: 0.2573Epoch 00009: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 130us/step - loss: 1.5880 - categorical_crossentropy: 1.5880 - acc: 0.2584 - val_loss: 1.5947 - val_categorical_crossentropy: 1.5947 - val_acc: 0.2536\n",
      "Epoch 10/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5856 - categorical_crossentropy: 1.5856 - acc: 0.2581 ETA: 1s - loss: 1.5692 - categorical_crEpoch 00010: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 135us/step - loss: 1.5859 - categorical_crossentropy: 1.5859 - acc: 0.2577 - val_loss: 1.5890 - val_categorical_crossentropy: 1.5890 - val_acc: 0.2381\n",
      "Epoch 11/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5844 - categorical_crossentropy: 1.5844 - acc: 0.2551Epoch 00011: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 137us/step - loss: 1.5841 - categorical_crossentropy: 1.5841 - acc: 0.2556 - val_loss: 1.5814 - val_categorical_crossentropy: 1.5814 - val_acc: 0.2647\n",
      "Epoch 12/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5816 - categorical_crossentropy: 1.5816 - acc: 0.2638Epoch 00012: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 133us/step - loss: 1.5811 - categorical_crossentropy: 1.5811 - acc: 0.2631 - val_loss: 1.5829 - val_categorical_crossentropy: 1.5829 - val_acc: 0.2647\n",
      "Epoch 13/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5818 - categorical_crossentropy: 1.5818 - acc: 0.2602Epoch 00013: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 132us/step - loss: 1.5812 - categorical_crossentropy: 1.5812 - acc: 0.2629 - val_loss: 1.5828 - val_categorical_crossentropy: 1.5828 - val_acc: 0.2680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5805 - categorical_crossentropy: 1.5805 - acc: 0.2592Epoch 00014: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 134us/step - loss: 1.5799 - categorical_crossentropy: 1.5799 - acc: 0.2593 - val_loss: 1.5778 - val_categorical_crossentropy: 1.5778 - val_acc: 0.2802\n",
      "Epoch 15/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5783 - categorical_crossentropy: 1.5783 - acc: 0.2654Epoch 00015: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 131us/step - loss: 1.5785 - categorical_crossentropy: 1.5785 - acc: 0.2659 - val_loss: 1.5837 - val_categorical_crossentropy: 1.5837 - val_acc: 0.2658\n",
      "Epoch 16/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5783 - categorical_crossentropy: 1.5783 - acc: 0.2620Epoch 00016: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 137us/step - loss: 1.5783 - categorical_crossentropy: 1.5783 - acc: 0.2620 - val_loss: 1.5862 - val_categorical_crossentropy: 1.5862 - val_acc: 0.2436\n",
      "Epoch 17/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5764 - categorical_crossentropy: 1.5764 - acc: 0.2604Epoch 00017: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 132us/step - loss: 1.5758 - categorical_crossentropy: 1.5758 - acc: 0.2616 - val_loss: 1.5918 - val_categorical_crossentropy: 1.5918 - val_acc: 0.2525\n",
      "Epoch 18/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5762 - categorical_crossentropy: 1.5762 - acc: 0.2610Epoch 00018: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 136us/step - loss: 1.5763 - categorical_crossentropy: 1.5763 - acc: 0.2610 - val_loss: 1.5901 - val_categorical_crossentropy: 1.5901 - val_acc: 0.2602\n",
      "Epoch 19/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5771 - categorical_crossentropy: 1.5771 - acc: 0.2604Epoch 00019: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 139us/step - loss: 1.5773 - categorical_crossentropy: 1.5773 - acc: 0.2597 - val_loss: 1.5784 - val_categorical_crossentropy: 1.5784 - val_acc: 0.2735\n",
      "Epoch 20/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5776 - categorical_crossentropy: 1.5776 - acc: 0.2629Epoch 00020: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 134us/step - loss: 1.5775 - categorical_crossentropy: 1.5775 - acc: 0.2626 - val_loss: 1.5863 - val_categorical_crossentropy: 1.5863 - val_acc: 0.2602\n",
      "Epoch 21/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5747 - categorical_crossentropy: 1.5747 - acc: 0.2676Epoch 00021: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 135us/step - loss: 1.5755 - categorical_crossentropy: 1.5755 - acc: 0.2667 - val_loss: 1.5830 - val_categorical_crossentropy: 1.5830 - val_acc: 0.2536\n",
      "Epoch 22/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5770 - categorical_crossentropy: 1.5770 - acc: 0.2597Epoch 00022: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 134us/step - loss: 1.5774 - categorical_crossentropy: 1.5774 - acc: 0.2590 - val_loss: 1.5908 - val_categorical_crossentropy: 1.5908 - val_acc: 0.2425\n",
      "Epoch 23/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5765 - categorical_crossentropy: 1.5765 - acc: 0.2635Epoch 00023: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 133us/step - loss: 1.5770 - categorical_crossentropy: 1.5770 - acc: 0.2637 - val_loss: 1.5909 - val_categorical_crossentropy: 1.5909 - val_acc: 0.2547\n",
      "Epoch 24/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5762 - categorical_crossentropy: 1.5762 - acc: 0.2646Epoch 00024: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 137us/step - loss: 1.5754 - categorical_crossentropy: 1.5754 - acc: 0.2641 - val_loss: 1.5799 - val_categorical_crossentropy: 1.5799 - val_acc: 0.2757\n",
      "Epoch 25/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5774 - categorical_crossentropy: 1.5774 - acc: 0.2587Epoch 00025: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 131us/step - loss: 1.5765 - categorical_crossentropy: 1.5765 - acc: 0.2605 - val_loss: 1.5782 - val_categorical_crossentropy: 1.5782 - val_acc: 0.2680\n",
      "Epoch 26/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5773 - categorical_crossentropy: 1.5773 - acc: 0.2632Epoch 00026: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 133us/step - loss: 1.5764 - categorical_crossentropy: 1.5764 - acc: 0.2643 - val_loss: 1.5952 - val_categorical_crossentropy: 1.5952 - val_acc: 0.2414\n",
      "Epoch 27/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5753 - categorical_crossentropy: 1.5753 - acc: 0.2581Epoch 00027: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 133us/step - loss: 1.5756 - categorical_crossentropy: 1.5756 - acc: 0.2574 - val_loss: 1.5783 - val_categorical_crossentropy: 1.5783 - val_acc: 0.2658\n",
      "Epoch 28/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5767 - categorical_crossentropy: 1.5767 - acc: 0.2690Epoch 00028: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 135us/step - loss: 1.5770 - categorical_crossentropy: 1.5770 - acc: 0.2689 - val_loss: 1.5793 - val_categorical_crossentropy: 1.5793 - val_acc: 0.2669\n",
      "Epoch 29/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5758 - categorical_crossentropy: 1.5758 - acc: 0.2617Epoch 00029: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 133us/step - loss: 1.5760 - categorical_crossentropy: 1.5760 - acc: 0.2626 - val_loss: 1.5826 - val_categorical_crossentropy: 1.5826 - val_acc: 0.2525\n",
      "Epoch 30/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5762 - categorical_crossentropy: 1.5762 - acc: 0.2651Epoch 00030: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 129us/step - loss: 1.5754 - categorical_crossentropy: 1.5754 - acc: 0.2658 - val_loss: 1.5807 - val_categorical_crossentropy: 1.5807 - val_acc: 0.2636\n",
      "Epoch 31/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5759 - categorical_crossentropy: 1.5759 - acc: 0.2645 ETA: 0s - loss: 1.5740 - categorical_crosseEpoch 00031: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 135us/step - loss: 1.5746 - categorical_crossentropy: 1.5746 - acc: 0.2647 - val_loss: 1.5786 - val_categorical_crossentropy: 1.5786 - val_acc: 0.2835\n",
      "Epoch 32/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5750 - categorical_crossentropy: 1.5750 - acc: 0.2630Epoch 00032: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 135us/step - loss: 1.5751 - categorical_crossentropy: 1.5751 - acc: 0.2629 - val_loss: 1.5850 - val_categorical_crossentropy: 1.5850 - val_acc: 0.2757\n",
      "Epoch 33/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5755 - categorical_crossentropy: 1.5755 - acc: 0.2661Epoch 00033: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 151us/step - loss: 1.5755 - categorical_crossentropy: 1.5755 - acc: 0.2677 - val_loss: 1.5799 - val_categorical_crossentropy: 1.5799 - val_acc: 0.2669\n",
      "Epoch 34/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5726 - categorical_crossentropy: 1.5726 - acc: 0.2705Epoch 00034: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 148us/step - loss: 1.5728 - categorical_crossentropy: 1.5728 - acc: 0.2703 - val_loss: 1.5860 - val_categorical_crossentropy: 1.5860 - val_acc: 0.2514\n",
      "Epoch 35/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5749 - categorical_crossentropy: 1.5749 - acc: 0.2605Epoch 00035: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 155us/step - loss: 1.5754 - categorical_crossentropy: 1.5754 - acc: 0.2594 - val_loss: 1.5805 - val_categorical_crossentropy: 1.5805 - val_acc: 0.2647\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5766 - categorical_crossentropy: 1.5766 - acc: 0.2650Epoch 00036: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 147us/step - loss: 1.5755 - categorical_crossentropy: 1.5755 - acc: 0.2664 - val_loss: 1.5800 - val_categorical_crossentropy: 1.5800 - val_acc: 0.2791\n",
      "Epoch 37/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5749 - categorical_crossentropy: 1.5749 - acc: 0.2674Epoch 00037: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 139us/step - loss: 1.5749 - categorical_crossentropy: 1.5749 - acc: 0.2664 - val_loss: 1.5769 - val_categorical_crossentropy: 1.5769 - val_acc: 0.2769\n",
      "Epoch 38/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5747 - categorical_crossentropy: 1.5747 - acc: 0.2619Epoch 00038: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 135us/step - loss: 1.5745 - categorical_crossentropy: 1.5745 - acc: 0.2634 - val_loss: 1.5790 - val_categorical_crossentropy: 1.5790 - val_acc: 0.2669\n",
      "Epoch 39/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5735 - categorical_crossentropy: 1.5735 - acc: 0.2672Epoch 00039: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 138us/step - loss: 1.5735 - categorical_crossentropy: 1.5735 - acc: 0.2664 - val_loss: 1.5795 - val_categorical_crossentropy: 1.5795 - val_acc: 0.2669\n",
      "Epoch 40/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5740 - categorical_crossentropy: 1.5740 - acc: 0.2676Epoch 00040: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 139us/step - loss: 1.5737 - categorical_crossentropy: 1.5737 - acc: 0.2680 - val_loss: 1.5866 - val_categorical_crossentropy: 1.5866 - val_acc: 0.2625\n",
      "Epoch 41/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5734 - categorical_crossentropy: 1.5734 - acc: 0.2675Epoch 00041: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 145us/step - loss: 1.5737 - categorical_crossentropy: 1.5737 - acc: 0.2679 - val_loss: 1.5960 - val_categorical_crossentropy: 1.5960 - val_acc: 0.2602\n",
      "Epoch 42/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5743 - categorical_crossentropy: 1.5743 - acc: 0.2673Epoch 00042: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 138us/step - loss: 1.5742 - categorical_crossentropy: 1.5742 - acc: 0.2672 - val_loss: 1.5806 - val_categorical_crossentropy: 1.5806 - val_acc: 0.2713\n",
      "Epoch 43/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5748 - categorical_crossentropy: 1.5748 - acc: 0.2632Epoch 00043: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 132us/step - loss: 1.5750 - categorical_crossentropy: 1.5750 - acc: 0.2630 - val_loss: 1.5818 - val_categorical_crossentropy: 1.5818 - val_acc: 0.2780\n",
      "Epoch 44/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5745 - categorical_crossentropy: 1.5745 - acc: 0.2598Epoch 00044: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 145us/step - loss: 1.5748 - categorical_crossentropy: 1.5748 - acc: 0.2597 - val_loss: 1.5858 - val_categorical_crossentropy: 1.5858 - val_acc: 0.2835\n",
      "Epoch 45/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5749 - categorical_crossentropy: 1.5749 - acc: 0.2632Epoch 00045: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 145us/step - loss: 1.5749 - categorical_crossentropy: 1.5749 - acc: 0.2639 - val_loss: 1.5831 - val_categorical_crossentropy: 1.5831 - val_acc: 0.2614\n",
      "Epoch 46/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5740 - categorical_crossentropy: 1.5740 - acc: 0.2636Epoch 00046: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 136us/step - loss: 1.5738 - categorical_crossentropy: 1.5738 - acc: 0.2637 - val_loss: 1.5826 - val_categorical_crossentropy: 1.5826 - val_acc: 0.2658\n",
      "Epoch 47/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5753 - categorical_crossentropy: 1.5753 - acc: 0.2620Epoch 00047: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 133us/step - loss: 1.5754 - categorical_crossentropy: 1.5754 - acc: 0.2615 - val_loss: 1.5851 - val_categorical_crossentropy: 1.5851 - val_acc: 0.2591\n",
      "Epoch 48/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5745 - categorical_crossentropy: 1.5745 - acc: 0.2687Epoch 00048: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 132us/step - loss: 1.5749 - categorical_crossentropy: 1.5749 - acc: 0.2685 - val_loss: 1.5788 - val_categorical_crossentropy: 1.5788 - val_acc: 0.2591\n",
      "Epoch 49/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5734 - categorical_crossentropy: 1.5734 - acc: 0.2646Epoch 00049: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 134us/step - loss: 1.5735 - categorical_crossentropy: 1.5735 - acc: 0.2645 - val_loss: 1.5827 - val_categorical_crossentropy: 1.5827 - val_acc: 0.2647\n",
      "Epoch 50/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5752 - categorical_crossentropy: 1.5752 - acc: 0.2652Epoch 00050: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 137us/step - loss: 1.5752 - categorical_crossentropy: 1.5752 - acc: 0.2647 - val_loss: 1.5793 - val_categorical_crossentropy: 1.5793 - val_acc: 0.2658\n",
      "Epoch 51/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5732 - categorical_crossentropy: 1.5732 - acc: 0.2641Epoch 00051: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 132us/step - loss: 1.5733 - categorical_crossentropy: 1.5733 - acc: 0.2636 - val_loss: 1.5804 - val_categorical_crossentropy: 1.5804 - val_acc: 0.2602\n",
      "Epoch 52/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5755 - categorical_crossentropy: 1.5755 - acc: 0.2649Epoch 00052: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 135us/step - loss: 1.5749 - categorical_crossentropy: 1.5749 - acc: 0.2659 - val_loss: 1.5813 - val_categorical_crossentropy: 1.5813 - val_acc: 0.2591\n",
      "Epoch 53/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5729 - categorical_crossentropy: 1.5729 - acc: 0.2646Epoch 00053: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 140us/step - loss: 1.5728 - categorical_crossentropy: 1.5728 - acc: 0.2642 - val_loss: 1.5849 - val_categorical_crossentropy: 1.5849 - val_acc: 0.2647\n",
      "Epoch 54/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5720 - categorical_crossentropy: 1.5720 - acc: 0.2704Epoch 00054: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 134us/step - loss: 1.5716 - categorical_crossentropy: 1.5716 - acc: 0.2712 - val_loss: 1.5808 - val_categorical_crossentropy: 1.5808 - val_acc: 0.2868\n",
      "Epoch 55/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5730 - categorical_crossentropy: 1.5730 - acc: 0.2671Epoch 00055: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 134us/step - loss: 1.5727 - categorical_crossentropy: 1.5727 - acc: 0.2669 - val_loss: 1.5767 - val_categorical_crossentropy: 1.5767 - val_acc: 0.2757\n",
      "Epoch 56/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5734 - categorical_crossentropy: 1.5734 - acc: 0.2678Epoch 00056: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 132us/step - loss: 1.5734 - categorical_crossentropy: 1.5734 - acc: 0.2669 - val_loss: 1.5896 - val_categorical_crossentropy: 1.5896 - val_acc: 0.2691\n",
      "Epoch 57/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5743 - categorical_crossentropy: 1.5743 - acc: 0.2634Epoch 00057: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 133us/step - loss: 1.5740 - categorical_crossentropy: 1.5740 - acc: 0.2636 - val_loss: 1.5779 - val_categorical_crossentropy: 1.5779 - val_acc: 0.2724\n",
      "Epoch 58/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5749 - categorical_crossentropy: 1.5749 - acc: 0.2688Epoch 00058: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 133us/step - loss: 1.5745 - categorical_crossentropy: 1.5745 - acc: 0.2693 - val_loss: 1.5776 - val_categorical_crossentropy: 1.5776 - val_acc: 0.2724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5735 - categorical_crossentropy: 1.5735 - acc: 0.2655Epoch 00059: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 131us/step - loss: 1.5736 - categorical_crossentropy: 1.5736 - acc: 0.2657 - val_loss: 1.5879 - val_categorical_crossentropy: 1.5879 - val_acc: 0.2780\n",
      "Epoch 60/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5731 - categorical_crossentropy: 1.5731 - acc: 0.2656Epoch 00060: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 137us/step - loss: 1.5728 - categorical_crossentropy: 1.5728 - acc: 0.2656 - val_loss: 1.5786 - val_categorical_crossentropy: 1.5786 - val_acc: 0.2658\n",
      "Epoch 61/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5740 - categorical_crossentropy: 1.5740 - acc: 0.2649Epoch 00061: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 135us/step - loss: 1.5731 - categorical_crossentropy: 1.5731 - acc: 0.2651 - val_loss: 1.5800 - val_categorical_crossentropy: 1.5800 - val_acc: 0.2691\n",
      "Epoch 62/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5720 - categorical_crossentropy: 1.5720 - acc: 0.2750Epoch 00062: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 137us/step - loss: 1.5726 - categorical_crossentropy: 1.5726 - acc: 0.2741 - val_loss: 1.5797 - val_categorical_crossentropy: 1.5797 - val_acc: 0.2924\n",
      "Epoch 63/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5741 - categorical_crossentropy: 1.5741 - acc: 0.2622Epoch 00063: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 136us/step - loss: 1.5739 - categorical_crossentropy: 1.5739 - acc: 0.2626 - val_loss: 1.5881 - val_categorical_crossentropy: 1.5881 - val_acc: 0.2724\n",
      "Epoch 64/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5736 - categorical_crossentropy: 1.5736 - acc: 0.2658Epoch 00064: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 146us/step - loss: 1.5739 - categorical_crossentropy: 1.5739 - acc: 0.2651 - val_loss: 1.5842 - val_categorical_crossentropy: 1.5842 - val_acc: 0.2713\n",
      "Epoch 65/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5736 - categorical_crossentropy: 1.5736 - acc: 0.2690Epoch 00065: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 135us/step - loss: 1.5730 - categorical_crossentropy: 1.5730 - acc: 0.2677 - val_loss: 1.5814 - val_categorical_crossentropy: 1.5814 - val_acc: 0.2746\n",
      "Epoch 66/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5738 - categorical_crossentropy: 1.5738 - acc: 0.2668Epoch 00066: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 161us/step - loss: 1.5733 - categorical_crossentropy: 1.5733 - acc: 0.2668 - val_loss: 1.5804 - val_categorical_crossentropy: 1.5804 - val_acc: 0.2780\n",
      "Epoch 67/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5742 - categorical_crossentropy: 1.5742 - acc: 0.2704Epoch 00067: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 161us/step - loss: 1.5730 - categorical_crossentropy: 1.5730 - acc: 0.2725 - val_loss: 1.5777 - val_categorical_crossentropy: 1.5777 - val_acc: 0.2780\n",
      "Epoch 68/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5731 - categorical_crossentropy: 1.5731 - acc: 0.2667Epoch 00068: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 148us/step - loss: 1.5732 - categorical_crossentropy: 1.5732 - acc: 0.2657 - val_loss: 1.5748 - val_categorical_crossentropy: 1.5748 - val_acc: 0.2735\n",
      "Epoch 69/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5749 - categorical_crossentropy: 1.5749 - acc: 0.2664Epoch 00069: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 146us/step - loss: 1.5745 - categorical_crossentropy: 1.5745 - acc: 0.2669 - val_loss: 1.5755 - val_categorical_crossentropy: 1.5755 - val_acc: 0.2769\n",
      "Epoch 70/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5748 - categorical_crossentropy: 1.5748 - acc: 0.2654Epoch 00070: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 157us/step - loss: 1.5748 - categorical_crossentropy: 1.5748 - acc: 0.2651 - val_loss: 1.5786 - val_categorical_crossentropy: 1.5786 - val_acc: 0.2636\n",
      "Epoch 71/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5714 - categorical_crossentropy: 1.5714 - acc: 0.2724Epoch 00071: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 152us/step - loss: 1.5713 - categorical_crossentropy: 1.5713 - acc: 0.2723 - val_loss: 1.5925 - val_categorical_crossentropy: 1.5925 - val_acc: 0.2625\n",
      "Epoch 72/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5748 - categorical_crossentropy: 1.5748 - acc: 0.2629Epoch 00072: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 145us/step - loss: 1.5741 - categorical_crossentropy: 1.5741 - acc: 0.2646 - val_loss: 1.5746 - val_categorical_crossentropy: 1.5746 - val_acc: 0.2625\n",
      "Epoch 73/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5717 - categorical_crossentropy: 1.5717 - acc: 0.2681Epoch 00073: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 141us/step - loss: 1.5722 - categorical_crossentropy: 1.5722 - acc: 0.2664 - val_loss: 1.5835 - val_categorical_crossentropy: 1.5835 - val_acc: 0.2591\n",
      "Epoch 74/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5729 - categorical_crossentropy: 1.5729 - acc: 0.2716Epoch 00074: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 140us/step - loss: 1.5733 - categorical_crossentropy: 1.5733 - acc: 0.2706 - val_loss: 1.5778 - val_categorical_crossentropy: 1.5778 - val_acc: 0.2669\n",
      "Epoch 75/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5716 - categorical_crossentropy: 1.5716 - acc: 0.2697Epoch 00075: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 130us/step - loss: 1.5723 - categorical_crossentropy: 1.5723 - acc: 0.2678 - val_loss: 1.5823 - val_categorical_crossentropy: 1.5823 - val_acc: 0.2846\n",
      "Epoch 76/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5728 - categorical_crossentropy: 1.5728 - acc: 0.2711Epoch 00076: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 145us/step - loss: 1.5725 - categorical_crossentropy: 1.5725 - acc: 0.2714 - val_loss: 1.5954 - val_categorical_crossentropy: 1.5954 - val_acc: 0.2569\n",
      "Epoch 77/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5718 - categorical_crossentropy: 1.5718 - acc: 0.2740Epoch 00077: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 129us/step - loss: 1.5724 - categorical_crossentropy: 1.5724 - acc: 0.2726 - val_loss: 1.5805 - val_categorical_crossentropy: 1.5805 - val_acc: 0.2724\n",
      "Epoch 78/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5728 - categorical_crossentropy: 1.5728 - acc: 0.2684Epoch 00078: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 129us/step - loss: 1.5728 - categorical_crossentropy: 1.5728 - acc: 0.2685 - val_loss: 1.5753 - val_categorical_crossentropy: 1.5753 - val_acc: 0.2713\n",
      "Epoch 79/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5747 - categorical_crossentropy: 1.5747 - acc: 0.2666Epoch 00079: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 146us/step - loss: 1.5747 - categorical_crossentropy: 1.5747 - acc: 0.2666 - val_loss: 1.5808 - val_categorical_crossentropy: 1.5808 - val_acc: 0.2802\n",
      "Epoch 80/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5713 - categorical_crossentropy: 1.5713 - acc: 0.2688Epoch 00080: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 153us/step - loss: 1.5719 - categorical_crossentropy: 1.5719 - acc: 0.2680 - val_loss: 1.5822 - val_categorical_crossentropy: 1.5822 - val_acc: 0.2702\n",
      "Epoch 81/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5729 - categorical_crossentropy: 1.5729 - acc: 0.2693Epoch 00081: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 129us/step - loss: 1.5731 - categorical_crossentropy: 1.5731 - acc: 0.2694 - val_loss: 1.5802 - val_categorical_crossentropy: 1.5802 - val_acc: 0.2636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5739 - categorical_crossentropy: 1.5739 - acc: 0.2620Epoch 00082: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 129us/step - loss: 1.5731 - categorical_crossentropy: 1.5731 - acc: 0.2629 - val_loss: 1.5818 - val_categorical_crossentropy: 1.5818 - val_acc: 0.2691\n",
      "Epoch 83/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5720 - categorical_crossentropy: 1.5720 - acc: 0.2683 ETA: 0s - loss: 1.5770 - categorical_crossentEpoch 00083: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 133us/step - loss: 1.5726 - categorical_crossentropy: 1.5726 - acc: 0.2667 - val_loss: 1.5797 - val_categorical_crossentropy: 1.5797 - val_acc: 0.2879\n",
      "Epoch 84/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5736 - categorical_crossentropy: 1.5736 - acc: 0.2702Epoch 00084: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 131us/step - loss: 1.5731 - categorical_crossentropy: 1.5731 - acc: 0.2712 - val_loss: 1.5785 - val_categorical_crossentropy: 1.5785 - val_acc: 0.2713\n",
      "Epoch 85/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5724 - categorical_crossentropy: 1.5724 - acc: 0.2732Epoch 00085: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 131us/step - loss: 1.5733 - categorical_crossentropy: 1.5733 - acc: 0.2712 - val_loss: 1.6009 - val_categorical_crossentropy: 1.6009 - val_acc: 0.2458\n",
      "Epoch 86/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5738 - categorical_crossentropy: 1.5738 - acc: 0.2675Epoch 00086: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 130us/step - loss: 1.5737 - categorical_crossentropy: 1.5737 - acc: 0.2672 - val_loss: 1.5798 - val_categorical_crossentropy: 1.5798 - val_acc: 0.2503\n",
      "Epoch 87/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5731 - categorical_crossentropy: 1.5731 - acc: 0.2689Epoch 00087: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 134us/step - loss: 1.5739 - categorical_crossentropy: 1.5739 - acc: 0.2680 - val_loss: 1.5767 - val_categorical_crossentropy: 1.5767 - val_acc: 0.2713\n",
      "Epoch 88/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5719 - categorical_crossentropy: 1.5719 - acc: 0.2699Epoch 00088: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 134us/step - loss: 1.5726 - categorical_crossentropy: 1.5726 - acc: 0.2683 - val_loss: 1.6016 - val_categorical_crossentropy: 1.6016 - val_acc: 0.2348\n",
      "Epoch 89/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5741 - categorical_crossentropy: 1.5741 - acc: 0.2652Epoch 00089: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 132us/step - loss: 1.5733 - categorical_crossentropy: 1.5733 - acc: 0.2650 - val_loss: 1.5817 - val_categorical_crossentropy: 1.5817 - val_acc: 0.2757\n",
      "Epoch 90/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5734 - categorical_crossentropy: 1.5734 - acc: 0.2687Epoch 00090: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 131us/step - loss: 1.5732 - categorical_crossentropy: 1.5732 - acc: 0.2689 - val_loss: 1.5788 - val_categorical_crossentropy: 1.5788 - val_acc: 0.2625\n",
      "Epoch 91/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5720 - categorical_crossentropy: 1.5720 - acc: 0.2693Epoch 00091: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 131us/step - loss: 1.5720 - categorical_crossentropy: 1.5720 - acc: 0.2693 - val_loss: 1.5742 - val_categorical_crossentropy: 1.5742 - val_acc: 0.2724\n",
      "Epoch 92/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5702 - categorical_crossentropy: 1.5702 - acc: 0.2705Epoch 00092: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 135us/step - loss: 1.5706 - categorical_crossentropy: 1.5706 - acc: 0.2700 - val_loss: 1.5863 - val_categorical_crossentropy: 1.5863 - val_acc: 0.2591\n",
      "Epoch 93/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5726 - categorical_crossentropy: 1.5726 - acc: 0.2686Epoch 00093: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 131us/step - loss: 1.5724 - categorical_crossentropy: 1.5724 - acc: 0.2687 - val_loss: 1.5874 - val_categorical_crossentropy: 1.5874 - val_acc: 0.2791\n",
      "Epoch 94/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5710 - categorical_crossentropy: 1.5710 - acc: 0.2739Epoch 00094: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 131us/step - loss: 1.5703 - categorical_crossentropy: 1.5703 - acc: 0.2743 - val_loss: 1.5839 - val_categorical_crossentropy: 1.5839 - val_acc: 0.2713\n",
      "Epoch 95/100\n",
      "7680/8122 [===========================>..] - ETA: 0s - loss: 1.5721 - categorical_crossentropy: 1.5721 - acc: 0.2711Epoch 00095: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 128us/step - loss: 1.5715 - categorical_crossentropy: 1.5715 - acc: 0.2715 - val_loss: 1.5812 - val_categorical_crossentropy: 1.5812 - val_acc: 0.2757\n",
      "Epoch 96/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5732 - categorical_crossentropy: 1.5732 - acc: 0.2715Epoch 00096: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 128us/step - loss: 1.5729 - categorical_crossentropy: 1.5729 - acc: 0.2715 - val_loss: 1.5862 - val_categorical_crossentropy: 1.5862 - val_acc: 0.2614\n",
      "Epoch 97/100\n",
      "7808/8122 [===========================>..] - ETA: 0s - loss: 1.5704 - categorical_crossentropy: 1.5704 - acc: 0.2679Epoch 00097: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 128us/step - loss: 1.5705 - categorical_crossentropy: 1.5705 - acc: 0.2677 - val_loss: 1.5767 - val_categorical_crossentropy: 1.5767 - val_acc: 0.2890\n",
      "Epoch 98/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5700 - categorical_crossentropy: 1.5700 - acc: 0.2696Epoch 00098: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 130us/step - loss: 1.5703 - categorical_crossentropy: 1.5703 - acc: 0.2691 - val_loss: 1.5768 - val_categorical_crossentropy: 1.5768 - val_acc: 0.2724\n",
      "Epoch 99/100\n",
      "7936/8122 [============================>.] - ETA: 0s - loss: 1.5706 - categorical_crossentropy: 1.5706 - acc: 0.2704Epoch 00099: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 132us/step - loss: 1.5705 - categorical_crossentropy: 1.5705 - acc: 0.2712 - val_loss: 1.5843 - val_categorical_crossentropy: 1.5843 - val_acc: 0.2481\n",
      "Epoch 100/100\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5710 - categorical_crossentropy: 1.5710 - acc: 0.2716Epoch 00100: val_acc did not improve\n",
      "8122/8122 [==============================] - 1s 129us/step - loss: 1.5711 - categorical_crossentropy: 1.5711 - acc: 0.2715 - val_loss: 1.6053 - val_categorical_crossentropy: 1.6053 - val_acc: 0.2470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16346eb70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "in_sentence = Input(shape=(MAX_WORD_PER_SENTENCE,), dtype='int32')\n",
    "sentence = layers.Lambda(lambda x: x[:, :MAX_SENTENCE_PER_SESSION])(in_sentence)\n",
    "e = Embedding(input_dim=nb_words,\n",
    "              output_dim=EMBEDDING_DIM,\n",
    "              input_length=MAX_WORD_PER_SENTENCE,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False)(sentence)\n",
    "\n",
    "gru_output = e\n",
    "if False:\n",
    "    gru_output = GRU(50, return_sequences=True)(gru_output)\n",
    "gru_output = layers.Bidirectional(GRU(8, return_sequences=True))(gru_output)\n",
    "gru_output = TimeDistributed(Dense(16))(gru_output)\n",
    "gru_output = AttLayer()(gru_output)\n",
    "\n",
    "# gru_output = layers.concatenate([GRU(50)(gru_output), tf.keras.backend.constant([[1]])])\n",
    "encoded_model = Model(inputs=[in_sentence], outputs=[gru_output])\n",
    "print(encoded_model.summary())\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SENTENCE_PER_SESSION, MAX_WORD_PER_SENTENCE), dtype='int32', name='glove')\n",
    "sentence_embedding_input = Input(shape=(MAX_SENTENCE_PER_SESSION, SENTENCE_EMBEDDING_SIZE), dtype='float32',\n",
    "                                name='sentence')\n",
    "session_embedding_input = Input(shape=(SESSION_EMBEDDING_SIZE,), dtype='float32', name='session')\n",
    "\n",
    "naive = True\n",
    "\n",
    "if not naive:\n",
    "    seq_encoded = TimeDistributed(encoded_model)(sequence_input)\n",
    "    seq_encoded = layers.concatenate([seq_encoded, sentence_embedding_input], axis=2)\n",
    "else:\n",
    "    seq_encoded = sentence_embedding_input\n",
    "seq_encoded = Dropout(0.2)(seq_encoded)\n",
    "seq_encoded = layers.Bidirectional(GRU(8, return_sequences=True))(seq_encoded)\n",
    "seq_encoded = AttLayer()(seq_encoded)\n",
    "seq_encoded = layers.concatenate([seq_encoded, session_embedding_input], axis=1)\n",
    "seq_encoded = Dropout(0.2)(seq_encoded)\n",
    "x = seq_encoded\n",
    "gru_output = Dense(16, activation='relu')(x)\n",
    "gru_output = BatchNormalization()(gru_output)\n",
    "gru_output = Dense(6, activation='softmax', name='softmax_output')(gru_output)\n",
    "if REGRESSION:\n",
    "    gru_output = Dense(1, activation='sigmoid', name='scalar_output')(gru_output)\n",
    "\n",
    "model = Model(inputs=[sequence_input, sentence_embedding_input, session_embedding_input], outputs=[gru_output])\n",
    "print(model.summary())\n",
    "\n",
    "if REGRESSION:\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.rmsprop(),\n",
    "                  metrics=[keras.metrics.mse, keras.metrics.binary_crossentropy])\n",
    "else:\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.rmsprop(),\n",
    "                  metrics=[keras.metrics.categorical_crossentropy, \"accuracy\"])\n",
    "model.fit(X_train,\n",
    "          {'softmax_output': y_train},\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_data=(X_test, {'softmax_output': y_test}),\n",
    "          callbacks=callbacks_list\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SESSION_EMBEDDING_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding_input = Input(shape=(MAX_SENTENCE_PER_SESSION, SENTENCE_EMBEDDING_SIZE), dtype='float32',\n",
    "                                name='session')\n",
    "session_embedding_input = Input(shape=(SESSION_EMBEDDING_SIZE,), dtype='float32', name='sentence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "naive = True\n",
    "if not naive:\n",
    "    seq_encoded = TimeDistributed(encoded_model)(sequence_input)\n",
    "    seq_encoded = layers.concatenate([seq_encoded, sentence_embedding_input], axis=2)\n",
    "else:\n",
    "    seq_encoded = sentence_embedding_input\n",
    "seq_encoded = Dropout(0.2)(seq_encoded)\n",
    "seq_encoded = layers.Bidirectional(GRU(50, return_sequences=True))(seq_encoded)\n",
    "seq_encoded = AttLayer()(seq_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9025, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_session_aux_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTENCE_EMBEDDING_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKKK\n",
      "Tensor(\"att_layer_25/ExpandDims:0\", shape=(?, 1, 1), dtype=float32)\n",
      "Tensor(\"att_layer_25/Exp:0\", shape=(?, 40, 1), dtype=float32)\n",
      "DONE\n",
      "Tensor(\"att_layer_25/multiply_14/mul:0\", shape=(?, 40, 100), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "lambda_57 (Lambda)           (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_21 (Embedding)     (None, 40, 100)           113400    \n",
      "_________________________________________________________________\n",
      "bidirectional_25 (Bidirectio (None, 40, 100)           45300     \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 40, 100)           10100     \n",
      "_________________________________________________________________\n",
      "att_layer_25 (AttLayer)      (None, 100)               100       \n",
      "=================================================================\n",
      "Total params: 168,900\n",
      "Trainable params: 55,500\n",
      "Non-trainable params: 113,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "OKKK\n",
      "Tensor(\"time_distributed_29/att_layer_25/ExpandDims:0\", shape=(?, 1, 1), dtype=float32)\n",
      "Tensor(\"time_distributed_29/att_layer_25/Exp:0\", shape=(?, ?, 1), dtype=float32)\n",
      "DONE\n",
      "Tensor(\"time_distributed_29/att_layer_25/multiply_15/mul:0\", shape=(?, ?, 100), dtype=float32)\n",
      "OKKK\n",
      "Tensor(\"att_layer_26/ExpandDims:0\", shape=(?, 1, 1), dtype=float32)\n",
      "Tensor(\"att_layer_26/Exp:0\", shape=(?, 20, 1), dtype=float32)\n",
      "DONE\n",
      "Tensor(\"att_layer_26/multiply_16/mul:0\", shape=(?, 20, 100), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentences (InputLayer)          (None, 20, 40)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_29 (TimeDistri (None, 20, 100)      168900      sentences[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aux (InputLayer)                (None, 20, 10)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 20, 110)      0           time_distributed_29[0][0]        \n",
      "                                                                 aux[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 20, 110)      0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_26 (Bidirectional (None, 20, 100)      48300       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "att_layer_26 (AttLayer)         (None, 100)          100         bidirectional_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "softmax_output (Dense)          (None, 6)            606         att_layer_26[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 217,906\n",
      "Trainable params: 104,506\n",
      "Non-trainable params: 113,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 54 samples, validate on 6 samples\n",
      "Epoch 1/30\n",
      "Epoch 00001: val_acc improved from -inf to 0.16667, saving model to imp-balanced-01-0.17.hdf5\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 1.8406 - categorical_crossentropy: 1.8406 - acc: 0.0000e+00 - val_loss: 1.7706 - val_categorical_crossentropy: 1.7706 - val_acc: 0.1667\n",
      "Epoch 2/30\n",
      "Epoch 00002: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7716 - categorical_crossentropy: 1.7716 - acc: 0.2037 - val_loss: 1.7737 - val_categorical_crossentropy: 1.7737 - val_acc: 0.1667\n",
      "Epoch 3/30\n",
      "Epoch 00003: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7342 - categorical_crossentropy: 1.7342 - acc: 0.2407 - val_loss: 1.7676 - val_categorical_crossentropy: 1.7676 - val_acc: 0.1667\n",
      "Epoch 4/30\n",
      "Epoch 00004: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7030 - categorical_crossentropy: 1.7030 - acc: 0.2778 - val_loss: 1.7685 - val_categorical_crossentropy: 1.7685 - val_acc: 0.1667\n",
      "Epoch 5/30\n",
      "Epoch 00005: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6700 - categorical_crossentropy: 1.6700 - acc: 0.1852 - val_loss: 1.7496 - val_categorical_crossentropy: 1.7496 - val_acc: 0.1667\n",
      "Epoch 6/30\n",
      "Epoch 00006: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6476 - categorical_crossentropy: 1.6476 - acc: 0.1852 - val_loss: 1.7568 - val_categorical_crossentropy: 1.7568 - val_acc: 0.0000e+00\n",
      "Epoch 7/30\n",
      "Epoch 00007: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6274 - categorical_crossentropy: 1.6274 - acc: 0.2222 - val_loss: 1.7327 - val_categorical_crossentropy: 1.7327 - val_acc: 0.1667\n",
      "Epoch 8/30\n",
      "Epoch 00008: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6150 - categorical_crossentropy: 1.6150 - acc: 0.2593 - val_loss: 1.7514 - val_categorical_crossentropy: 1.7514 - val_acc: 0.0000e+00\n",
      "Epoch 9/30\n",
      "Epoch 00009: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6050 - categorical_crossentropy: 1.6050 - acc: 0.2407 - val_loss: 1.7158 - val_categorical_crossentropy: 1.7158 - val_acc: 0.1667\n",
      "Epoch 10/30\n",
      "Epoch 00010: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5964 - categorical_crossentropy: 1.5964 - acc: 0.3148 - val_loss: 1.8058 - val_categorical_crossentropy: 1.8058 - val_acc: 0.0000e+00\n",
      "Epoch 11/30\n",
      "Epoch 00011: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5969 - categorical_crossentropy: 1.5969 - acc: 0.2222 - val_loss: 1.7041 - val_categorical_crossentropy: 1.7041 - val_acc: 0.0000e+00\n",
      "Epoch 12/30\n",
      "Epoch 00012: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6027 - categorical_crossentropy: 1.6027 - acc: 0.2963 - val_loss: 1.8180 - val_categorical_crossentropy: 1.8180 - val_acc: 0.0000e+00\n",
      "Epoch 13/30\n",
      "Epoch 00013: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5833 - categorical_crossentropy: 1.5833 - acc: 0.2593 - val_loss: 1.7354 - val_categorical_crossentropy: 1.7354 - val_acc: 0.0000e+00\n",
      "Epoch 14/30\n",
      "Epoch 00014: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5774 - categorical_crossentropy: 1.5774 - acc: 0.3148 - val_loss: 1.8192 - val_categorical_crossentropy: 1.8192 - val_acc: 0.0000e+00\n",
      "Epoch 15/30\n",
      "Epoch 00015: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5705 - categorical_crossentropy: 1.5705 - acc: 0.2407 - val_loss: 1.7568 - val_categorical_crossentropy: 1.7568 - val_acc: 0.0000e+00\n",
      "Epoch 16/30\n",
      "Epoch 00016: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5676 - categorical_crossentropy: 1.5676 - acc: 0.3148 - val_loss: 1.8486 - val_categorical_crossentropy: 1.8486 - val_acc: 0.0000e+00\n",
      "Epoch 17/30\n",
      "Epoch 00017: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5609 - categorical_crossentropy: 1.5609 - acc: 0.2407 - val_loss: 1.7777 - val_categorical_crossentropy: 1.7777 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "Epoch 00018: val_acc did not improve\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.5562 - categorical_crossentropy: 1.5562 - acc: 0.3148 - val_loss: 1.8965 - val_categorical_crossentropy: 1.8965 - val_acc: 0.0000e+00\n",
      "Epoch 19/30\n",
      "Epoch 00019: val_acc did not improve\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.5636 - categorical_crossentropy: 1.5636 - acc: 0.2407 - val_loss: 1.8051 - val_categorical_crossentropy: 1.8051 - val_acc: 0.0000e+00\n",
      "Epoch 20/30\n",
      "Epoch 00020: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5596 - categorical_crossentropy: 1.5596 - acc: 0.3148 - val_loss: 1.9237 - val_categorical_crossentropy: 1.9237 - val_acc: 0.0000e+00\n",
      "Epoch 21/30\n",
      "Epoch 00021: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5535 - categorical_crossentropy: 1.5535 - acc: 0.2778 - val_loss: 1.8477 - val_categorical_crossentropy: 1.8477 - val_acc: 0.0000e+00\n",
      "Epoch 22/30\n",
      "Epoch 00022: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5540 - categorical_crossentropy: 1.5540 - acc: 0.2778 - val_loss: 1.9615 - val_categorical_crossentropy: 1.9615 - val_acc: 0.0000e+00\n",
      "Epoch 23/30\n",
      "Epoch 00023: val_acc did not improve\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.5517 - categorical_crossentropy: 1.5517 - acc: 0.2593 - val_loss: 1.8709 - val_categorical_crossentropy: 1.8709 - val_acc: 0.0000e+00\n",
      "Epoch 24/30\n",
      "Epoch 00024: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5462 - categorical_crossentropy: 1.5462 - acc: 0.2963 - val_loss: 1.9773 - val_categorical_crossentropy: 1.9773 - val_acc: 0.0000e+00\n",
      "Epoch 25/30\n",
      "Epoch 00025: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5361 - categorical_crossentropy: 1.5361 - acc: 0.2407 - val_loss: 1.9222 - val_categorical_crossentropy: 1.9222 - val_acc: 0.0000e+00\n",
      "Epoch 26/30\n",
      "Epoch 00026: val_acc did not improve\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.5413 - categorical_crossentropy: 1.5413 - acc: 0.3704 - val_loss: 2.0012 - val_categorical_crossentropy: 2.0012 - val_acc: 0.0000e+00\n",
      "Epoch 27/30\n",
      "Epoch 00027: val_acc did not improve\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.5303 - categorical_crossentropy: 1.5303 - acc: 0.2222 - val_loss: 1.9654 - val_categorical_crossentropy: 1.9654 - val_acc: 0.0000e+00\n",
      "Epoch 28/30\n",
      "Epoch 00028: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5230 - categorical_crossentropy: 1.5230 - acc: 0.3333 - val_loss: 2.0750 - val_categorical_crossentropy: 2.0750 - val_acc: 0.0000e+00\n",
      "Epoch 29/30\n",
      "Epoch 00029: val_acc did not improve\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.5271 - categorical_crossentropy: 1.5271 - acc: 0.2407 - val_loss: 1.9996 - val_categorical_crossentropy: 1.9996 - val_acc: 0.0000e+00\n",
      "Epoch 30/30\n",
      "Epoch 00030: val_acc did not improve\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5216 - categorical_crossentropy: 1.5216 - acc: 0.3704 - val_loss: 2.1119 - val_categorical_crossentropy: 2.1119 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.init = initializers.glorot_normal\n",
    "        super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[-1], 1),\n",
    "                                      initializer=\"glorot_normal\",\n",
    "                                      trainable=True)\n",
    "\n",
    "\n",
    "        super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.tanh(K.dot(x, self.W))\n",
    "        ai = K.exp(eij)\n",
    "        S = K.sum(ai, axis=1)\n",
    "        S = tf.expand_dims(S, 1)\n",
    "#         S = layers.Lambda(lambda x:K.sum(x, axis=1), output_shape=[ai.shape[1],1])(ai)\n",
    "        print(\"OKKK\")\n",
    "        print(S)\n",
    "        print(ai)\n",
    "        print(\"DONE\")\n",
    "\n",
    "        weights = ai / S\n",
    "        weighted_input =  layers.Multiply()([x,weights])\n",
    "        print(weighted_input)\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n",
    "\n",
    "\n",
    "in_sentence = Input(shape=(MAX_WORD_PER_SENTENCE,), dtype='int32')\n",
    "sentence = layers.Lambda(lambda x: x[:, :MAX_SENTENCE_PER_SESSION])(in_sentence)\n",
    "e = Embedding(input_dim=nb_words,\n",
    "              output_dim=EMBEDDING_DIM,\n",
    "              input_length=MAX_WORD_PER_SENTENCE,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False)(sentence)\n",
    "\n",
    "gru_output = e\n",
    "if False:\n",
    "    gru_output = GRU(50, return_sequences=True)(gru_output)\n",
    "gru_output = layers.Bidirectional(GRU(50, return_sequences=True))(gru_output)\n",
    "gru_output = TimeDistributed(Dense(100))(gru_output)\n",
    "gru_output = AttLayer()(gru_output)\n",
    "\n",
    "# gru_output = layers.concatenate([GRU(50)(gru_output), tf.keras.backend.constant([[1]])])\n",
    "encoded_model = Model(inputs=[in_sentence], outputs=[gru_output])\n",
    "print(encoded_model.summary())\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SENTENCE_PER_SESSION, MAX_WORD_PER_SENTENCE), dtype='int32', name='sentences')\n",
    "sequence_aux_input = Input(shape=(MAX_SENTENCE_PER_SESSION, 10), dtype='float32', name='aux')\n",
    "\n",
    "seq_encoded = TimeDistributed(encoded_model)(sequence_input)\n",
    "seq_encoded = layers.concatenate([seq_encoded, sequence_aux_input], axis=2)\n",
    "seq_encoded = Dropout(0.2)(seq_encoded)\n",
    "seq_encoded = layers.Bidirectional(GRU(50, return_sequences=True))(seq_encoded)\n",
    "seq_encoded = AttLayer()(seq_encoded)\n",
    "\n",
    "x = seq_encoded\n",
    "\n",
    "gru_output = Dense(6, activation='softmax', name='softmax_output')(x)\n",
    "if REGRESSION:\n",
    "    gru_output = Dense(1, activation='sigmoid', name='scalar_output')(gru_output)\n",
    "\n",
    "model = Model(inputs=[sequence_input, sequence_aux_input], outputs=[gru_output])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "if REGRESSION:\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.rmsprop(),\n",
    "                  metrics=[keras.metrics.mse, keras.metrics.binary_crossentropy])\n",
    "else:\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.rmsprop(),\n",
    "                  metrics=[keras.metrics.categorical_crossentropy, \"accuracy\"])\n",
    "\n",
    "\n",
    "def prepare(X):\n",
    "    return {\"sentences\": np.copy(X[:, :, :MAX_WORD_PER_SENTENCE]),\n",
    "            \"aux\": np.copy(np.array(X[:, :, MAX_WORD_PER_SENTENCE:], dtype=\"float\"))\n",
    "            }\n",
    "\n",
    "\n",
    "# here\n",
    "if REGRESSION:\n",
    "    y_train = np.argmax(y_train, axis=1).reshape([-1, 1])\n",
    "    y_test = np.argmax(y_test, axis=1).reshape([-1, 1])\n",
    "    y_train = y_train / 5.\n",
    "    y_test = y_test / 5.\n",
    "\n",
    "    model.fit(prepare(X_train),\n",
    "              {'scalar_output': y_train},\n",
    "              epochs=30,\n",
    "              batch_size=128,\n",
    "              validation_data=({'sentences': X_test}, {'scalar_output': y_test}),\n",
    "              callbacks=callbacks_list\n",
    "              )\n",
    "else:\n",
    "    model.fit(prepare(X_train),\n",
    "              {'softmax_output': y_train},\n",
    "              epochs=30,\n",
    "              batch_size=128,\n",
    "              validation_data=(prepare(X_test), {'softmax_output': y_test}),\n",
    "              callbacks=callbacks_list\n",
    "              )\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ExpandDims_1:0\", shape=(?, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = K.placeholder([None, 40,1])\n",
    "S = layers.Lambda(lambda x:K.sum(x, axis=1), output_shape=[40,1])(a)\n",
    "S = tf.expand_dims(S,1)\n",
    "print(S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_3:0' shape=(?, 40) dtype=int32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8122 samples, validate on 903 samples\n",
      "Epoch 1/30\n",
      "8064/8122 [============================>.] - ETA: 0s - loss: 1.5874 - categorical_crossentropy: 1.5874 - acc: 0.2496Epoch 00001: val_acc did not improve\n",
      "8122/8122 [==============================] - 24s 3ms/step - loss: 1.5878 - categorical_crossentropy: 1.5878 - acc: 0.2496 - val_loss: 1.5969 - val_categorical_crossentropy: 1.5969 - val_acc: 0.2303\n",
      "Epoch 2/30\n",
      "2432/8122 [=======>......................] - ETA: 17s - loss: 1.5872 - categorical_crossentropy: 1.5872 - acc: 0.2430"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fbc786e23999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'softmax_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m               )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def prepare(X):\n",
    "    return {\"sentences\": np.copy(X[:, :, :MAX_WORD_PER_SENTENCE]),\n",
    "            \"aux\": np.copy(np.array(X[:, :, MAX_WORD_PER_SENTENCE:], dtype=\"float\"))\n",
    "            }\n",
    "model.fit(prepare(X_train),\n",
    "              {'softmax_output': y_train},\n",
    "              epochs=5,\n",
    "              batch_size=128,\n",
    "              validation_data=(prepare(X_test), {'softmax_output': y_test}),\n",
    "              callbacks=callbacks_list\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'aux:0' shape=(?, 20, 10) dtype=float32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_aux_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'time_distributed_2/Reshape_1:0' shape=(?, 20, 40, 100) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'att_layer_1/Sum_1:0' shape=(?, 100) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sentences:0' shape=(?, 20, 40) dtype=int32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 40, 100)           113400    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 40, 100)           45300     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 40, 100)           10100     \n",
      "_________________________________________________________________\n",
      "att_layer_1 (AttLayer)       (None, 40, 100)           100       \n",
      "=================================================================\n",
      "Total params: 168,900\n",
      "Trainable params: 55,500\n",
      "Non-trainable params: 113,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'time_distributed_3/Reshape_1:0' shape=(?, 20, 40, 100) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TimeDistributed(encoded_model)(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-17806846e29b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y_true = y_test.argmax(axis=1)\n",
    "preds = model.predict(prepare(X_test))\n",
    "preds = preds.argmax(axis=1)\n",
    "cm = ConfusionMatrix(y_true, preds)\n",
    "cm.plot(backend='seaborn', normalized=True)\n",
    "plt.title('Confusion Matrix Stars prediction')\n",
    "plt.figure(figsize=(12, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6f31c8f4cca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y_true = y_train.argmax(axis=1)\n",
    "preds = model.predict(prepare(X_train))\n",
    "preds = preds.argmax(axis=1)\n",
    "cm = ConfusionMatrix(y_true, preds)\n",
    "cm.plot(backend='seaborn', normalized=True)\n",
    "plt.title('Confusion Matrix Stars prediction')\n",
    "plt.figure(figsize=(12, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.      0.      0.08    0.07    0.      0.    ]\n",
      "  [ 0.      1.      0.15    0.11    0.      0.    ]\n",
      "  [ 1.      0.      0.04    0.04    0.      0.    ]\n",
      "  ..., \n",
      "  [ 0.      1.      0.3525  0.27    0.      0.    ]\n",
      "  [ 1.      0.      0.0525  0.05    0.      0.    ]\n",
      "  [ 0.      1.      0.335   0.24    0.      0.    ]]\n",
      "\n",
      " [[ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  [ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  [ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  ..., \n",
      "  [ 0.      1.      0.165   0.15    0.      0.    ]\n",
      "  [ 1.      0.      0.0225  0.02    0.      0.    ]\n",
      "  [ 0.      1.      0.0325  0.02    0.      0.    ]]\n",
      "\n",
      " [[ 1.      0.      0.04    0.03    0.      0.    ]\n",
      "  [ 0.      1.      0.1475  0.11    0.      0.    ]\n",
      "  [ 1.      0.      0.025   0.02    0.      0.    ]\n",
      "  ..., \n",
      "  [ 0.      1.      0.045   0.04    0.      0.    ]\n",
      "  [ 1.      0.      0.0875  0.08    0.      0.    ]\n",
      "  [ 0.      1.      0.4225  0.3     0.      0.    ]]\n",
      "\n",
      " ..., \n",
      " [[ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  [ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  [ 1.      0.      0.0375  0.03    0.      0.    ]\n",
      "  ..., \n",
      "  [ 0.      1.      0.2375  0.17    0.      0.    ]\n",
      "  [ 1.      0.      0.04    0.04    0.      0.    ]\n",
      "  [ 0.      1.      0.0375  0.03    0.      0.    ]]\n",
      "\n",
      " [[ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  [ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  [ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  ..., \n",
      "  [ 0.      1.      0.025   0.02    0.      0.    ]\n",
      "  [ 1.      0.      0.1025  0.11    0.      0.    ]\n",
      "  [ 0.      1.      0.285   0.22    0.      0.    ]]\n",
      "\n",
      " [[ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  [ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  [ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  ..., \n",
      "  [ 0.      0.      0.      0.01    0.      0.    ]\n",
      "  [ 1.      0.      0.01    0.01    0.      0.    ]\n",
      "  [ 0.      1.      0.09    0.08    0.      0.    ]]]\n"
     ]
    }
   ],
   "source": [
    "def prepare(X):\n",
    "    aux_unnormalized = np.copy(np.array(X[:, :, MAX_WORD_PER_SENTENCE:], dtype=\"float\"))\n",
    "    aux_normalized = aux_unnormalized / np.max(aux_unnormalized, axis=(0,1))\n",
    "    print(aux_normalized)\n",
    "    \n",
    "    return {\"sentences\": np.copy(X[:, :, :MAX_WORD_PER_SENTENCE]),\n",
    "            \"aux\": aux_normalized\n",
    "            }\n",
    "X = np.concatenate((seqs, aux_embedding), axis=2)\n",
    "Y = df_rev_balanced.rating.values.astype(int)\n",
    "Y_cat = to_categorical(Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_cat, test_size=VALIDATION_SPLIT, random_state=9)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_cat, test_size=VALIDATION_SPLIT, random_state=9)\n",
    "\n",
    "p = prepare(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8122, 20, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p['aux'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 51120.        ,  51120.        ,   9695.745     ,   8527.13000001,\n",
       "         2423.        ,    160.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(p['aux'], axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 3]\n",
      "[2, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "Z = np.arange(15).reshape((5,3))\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "print(y_train)\n",
    "_, _, y_train, _ = train_test_split(\n",
    "    Z, y, test_size=0.33, random_state=42)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x195dbac50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEWCAYAAAB7QRxFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDJmSprgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19ca3a2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x195dbac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import h5py\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "%matplotlib inline\n",
    "y_true = y_test.argmax(axis=1)\n",
    "preds = model.predict(X_test)\n",
    "preds = preds.argmax(axis=1)\n",
    "cm = ConfusionMatrix(y_true, preds)\n",
    "cm.plot(backend='seaborn', normalized=True)\n",
    "plt.title('Confusion Matrix Stars prediction')\n",
    "plt.figure(figsize=(12, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
